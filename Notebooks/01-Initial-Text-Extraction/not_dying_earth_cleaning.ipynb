{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_text = \"\"\"Into thin air\n",
    "by\n",
    "Jon Krakauer\n",
    "\n",
    "\n",
    "Copyright (c) 1997 by Jon Krakauer\n",
    "\n",
    "All rights reserved under International and Pan-American Copyright\n",
    "Conventions.\n",
    "Published in the United States by Villard Books, a division of Random\n",
    "House, Inc New York, and simultaneously in Canada by Random House of\n",
    "Canada Limited, Toronto.\n",
    "ViLLard Books is a registered trademark of Random House, Inc. Portions\n",
    "of this work were originally published in Outside.\n",
    "Grateful acknowledgment is made to the following for permission to\n",
    "reprint previously published material:\n",
    "\n",
    "BATON WICKS PUBLICATIONS: Excerpts from Upon That Mountain by Eric\n",
    "Shipton (Hodder, London, 1943).  This title is now collected in the\n",
    "omnibus Eric Sbipton The Six Mountain Travel Books (Diadem, London, and\n",
    "the Mountaineers, Seattle, 1995).  Reprinted by permission of Nick\n",
    "Shipton and Baton Wicks Publications, Macclesfield, Cheshire, England.\n",
    "HAYNES PUBLISHING: Excerpts from Everest by Walt Unsworth.  Published\n",
    "by Oxford Illustrated Press, an imprint of Haynes Publishing,\n",
    "Sparkford, Nr Yeovil, Somerset, BA22 7jj.  Reprinted by permission of\n",
    "the author and publisher.\n",
    "SIMON AND SCHUSTER AND A. P. WATT LTD: Six lines from 'The Second\n",
    "Coming\" by William Butler Yeats, from The Collected Works of W B.\n",
    "Yeats, Volume 1: The Poems revised and edited by Richard J. Finneran.\n",
    "Copyright 1924 by Macmillan Publishing Company.  Copyright renewed 1952\n",
    "by Bertha Georgie Yeats.  Reprinted by permission of Simon and Schuster\n",
    "and A. P. Watt Ltd.\n",
    "\n",
    "on behalf of Michael Yeats.\n",
    "For Linda; and in memory of Andy Harris, Doug Hansen, Rob Hall, Yasuko\n",
    "Namba, Scott Fischer, Ngawang Topche Sherpa, Chen Yu-Nan, Bruce Herrod,\n",
    "and Lopsang jangbu Sherpa\n",
    "\n",
    "Library of Congress Cataloging-in-Publication Data Krakauer, Jon.\n",
    "\n",
    "Into thin air: a personal account of the Mount Everest disaster Jon\n",
    "Krakauer.\n",
    "\n",
    "P. CM.\n",
    "\n",
    "Includes bibliographical references.\n",
    "\n",
    "ISBN 0-679-45752-6\n",
    "\n",
    "1. Mountaineering accidents-Everest, Mount (China and Nepal).\n",
    "\n",
    "2. Mount Everest Expedition (1996).  3. Krakauer, Jon.  I. Title.\n",
    "\n",
    "GV199.44.E85K725 1997 796.5'2\"-095496--dc2 i 96-30031 Random House\n",
    "website address: http://www.randomhouse.com/\n",
    "\n",
    "Printed in the United States of America on acid-free paper\n",
    "\n",
    "Book design by Caroline Cunningham\n",
    "\n",
    "Men play at tragedy because they do not believe in the reality of life\n",
    "tragedy which is actually being staged in the civilized world.\n",
    "\n",
    "Jose Ortega Gasset\n",
    "\n",
    "INTRODUCTION\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions \n",
    "\n",
    "def open_book(filename):\n",
    "    with open(\"../../Resources/Raw/\"+filename+\".txt\", 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def remove_hyphenation(content):\n",
    "    # Define the regular expression pattern for hyphenated words across lines\n",
    "    # This pattern matches words ending with a hyphen followed by any whitespace and the continuation of the word\n",
    "    pattern = r'(\\w+)-\\s+(\\w+)'\n",
    "\n",
    "    # Substitute the pattern with the combined word\n",
    "    corrected_content = re.sub(pattern, r'\\1\\2', content)\n",
    "\n",
    "    return corrected_content\n",
    "\n",
    "# Function to load and read the content of an EPUB file\n",
    "def epub_loader(filepath):\n",
    "    # Read the EPUB file\n",
    "    book = epub.read_epub(r\"../../Resources/Raw/\"+filepath)\n",
    "\n",
    "    # Extract the text content from the EPUB file\n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            # Parse the HTML content using BeautifulSoup\n",
    "            soup = BeautifulSoup(item.content, 'html.parser')\n",
    "            # Get the text from the parsed HTML\n",
    "            text = soup.get_text()\n",
    "\n",
    "    # Return the extracted text\n",
    "    return text\n",
    "\n",
    "def remove_page_markers(text):\n",
    "    \"\"\"\n",
    "    This function removes any instances of markers like \"www.TaleBooks.comPage  3 ,  Adventures of Tom Sawyer, The - Mark Twain\"\n",
    "    and works for any \"Page\" number. It also removes a specific instance: \"Page  2 ,  Adventures of Tom Sawyer, The - Mark Twain \".\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    # Regex pattern to match the page markers\n",
    "    pattern = r\"www\\.TaleBooks\\.comPage\\s+\\d+\\s+,  Adventures of Tom Sawyer, The - Mark Twain\\s+\"\n",
    "    # Additional pattern for the specific instance\n",
    "    specific_pattern = r\"Page\\s+2\\s+,  Adventures of Tom Sawyer, The - Mark Twain\\s+\"\n",
    "\n",
    "    # Using regex to remove the page markers\n",
    "    cleaned_text = re.sub(pattern, \"\", text)\n",
    "    # Removing the specific instance\n",
    "    cleaned_text = re.sub(specific_pattern, \"\", cleaned_text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\n",
    "def pdf_reader(filepath, pages_to_ignore):\n",
    "    \"\"\"\n",
    "    Reads a PDF file and extracts the text from all pages except the first two.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): The path to the PDF file.\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted text from the PDF file.\n",
    "    \"\"\"\n",
    "    # Read the PDF file at the specified filepath\n",
    "    reader = PdfReader(r\"../../Resources/Raw/\" + filepath)\n",
    "    \n",
    "    # Get the total number of pages in the PDF\n",
    "    number_of_pages = len(reader.pages)\n",
    "\n",
    "    # Skip the first two pages and extract the text from the remaining pages\n",
    "    text = \"\"\n",
    "    for page_number in range(pages_to_ignore, number_of_pages):\n",
    "        page = reader.pages[page_number]\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def remove_initial_text(text):\n",
    "\n",
    "    # Find the end index of the removal text\n",
    "    end_index = text.find(removal_text) + len(removal_text)\n",
    "\n",
    "    # Remove the initial text if found, otherwise return the original text\n",
    "    if end_index > -1:\n",
    "        return text[end_index:].strip()\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Function to clean the extracted text from an EPUB file\n",
    "def clean_text(text):\n",
    "    # Split the text into paragraphs\n",
    "    paragraphs = text.split('\\n\\n\\n')\n",
    "    cleaned_paragraphs = []\n",
    "\n",
    "    # Clean each paragraph by removing extra whitespace\n",
    "    for paragraph in paragraphs:\n",
    "        cleaned_paragraph = re.sub(r'\\s+', ' ', paragraph.strip())\n",
    "        cleaned_paragraphs.append(cleaned_paragraph)\n",
    "\n",
    "    # Join the cleaned paragraphs and return the result\n",
    "    return '\\n'.join(cleaned_paragraphs)\n",
    "\n",
    "def remove_chapter_headers_and_citations(text):\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    cleaned_lines = []\n",
    "\n",
    "    # Remove 'CHAPTER [n]', 'PART [n]', and lines starting with '-' or '*' from each line\n",
    "    for line in lines:\n",
    "        if (not re.match(r'^CHAPTER \\b(X{0,3})(IX|IV|V?I{0,3})\\b', line, re.IGNORECASE) and\n",
    "            not re.match(r'^PART \\b(X{0,3})(IX|IV|V?I{0,3})\\b', line, re.IGNORECASE) and\n",
    "            not line.startswith('-') and not line.startswith('*')):\n",
    "            cleaned_lines.append(line)\n",
    "\n",
    "    # Join the cleaned lines and return the result\n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "def remove_unwanted_line_breaks(text):\n",
    "    \"\"\"\n",
    "    Removes line breaks from a text except when the line break is preceded by a period or a colon.\n",
    "    \n",
    "    :param text: str - The text to be processed.\n",
    "    :return: str - The processed text.\n",
    "    \"\"\"\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Initialize an empty string to hold the processed text\n",
    "    processed_text = ''\n",
    "\n",
    "    for line in lines:\n",
    "        # Strip leading and trailing whitespaces from the line\n",
    "        trimmed_line = line.strip()\n",
    "\n",
    "        if processed_text and processed_text[-1] in \".:\":\n",
    "            # Add the line with a line break if the previous sentence ends with a period or colon\n",
    "            processed_text += '\\n' + trimmed_line\n",
    "        else:\n",
    "            # Add a space before the line if the processed text is not empty\n",
    "            if processed_text:\n",
    "                processed_text += ' '\n",
    "            processed_text += trimmed_line\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "\n",
    "# Function to remove blank lines from the cleaned text\n",
    "def remove_blank_lines(text):\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    non_blank_lines = []\n",
    "\n",
    "    # Remove blank lines from the text\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            non_blank_lines.append(line)\n",
    "\n",
    "    # Join the non-blank lines and return the result\n",
    "    return '\\n'.join(non_blank_lines)\n",
    "\n",
    "def remove_file_paths_from_content(content):\n",
    "    # Define the regular expression pattern for the file paths\n",
    "    pattern = r'file:///C\\|/.+\\.txt'\n",
    "\n",
    "    # If the content is a string, split it into lines\n",
    "    if isinstance(content, str):\n",
    "        content = content.splitlines()\n",
    "\n",
    "    # Filter out lines that match the pattern\n",
    "    filtered_lines = [line for line in content if not re.search(pattern, line)]\n",
    "\n",
    "    # Join the filtered lines back into a single string\n",
    "    filtered_content = '\\n'.join(filtered_lines)\n",
    "\n",
    "    return filtered_content\n",
    "\n",
    "def remove_specific_patterns(content):\n",
    "    # Define the regular expression pattern for the specified strings\n",
    "    # This pattern matches one or more digits followed by space and uppercase letters,\n",
    "    # and possibly some special characters at the end\n",
    "    pattern = r'\\d+\\s+[A-Z\\s]+(?:\\d+\\'?)?'\n",
    "\n",
    "    # If the content is a string, split it into lines\n",
    "    if isinstance(content, str):\n",
    "        content = content.splitlines()\n",
    "\n",
    "    # Filter each line using the regular expression\n",
    "    filtered_lines = []\n",
    "    for line in content:\n",
    "        # Substitute matching patterns with an empty string\n",
    "        new_line = re.sub(pattern, '', line)\n",
    "        filtered_lines.append(new_line)\n",
    "\n",
    "    # Join the filtered lines back into a single string\n",
    "    filtered_content = '\\n'.join(filtered_lines)\n",
    "\n",
    "    return filtered_content\n",
    "\n",
    "# Function to save the cleaned text as a text file\n",
    "def save_as_txt(filename, text):\n",
    "    # Open the file in write mode and write the cleaned text\n",
    "    with open(\"../../Resources/Cleaned/\"+filename+\".txt\", 'w', encoding='utf-8') as file:\n",
    "        file.write(text.strip())\n",
    "        \n",
    "def remove_initial(text):\n",
    "    # Define the initial text to be removed\n",
    "    removal_text = \"\"\"The Killing Machine\n",
    "By Jack Vance\n",
    "Book 2 in the \"Demon Prince\" Series\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    # Find the end index of the removal text\n",
    "    end_index = text.find(removal_text) + len(removal_text)\n",
    "\n",
    "    # Remove the initial text if found, otherwise return the original text\n",
    "    if end_index > -1:\n",
    "        return text[end_index:].strip()\n",
    "    else:\n",
    "        return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmos_text = pdf_reader(\"cosmos.pdf\", 8)\n",
    "cosmos_text = remove_chapter_headers_and_citations(cosmos_text)\n",
    "cosmos_text = remove_unwanted_line_breaks(cosmos_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_text = pdf_reader(\"tom_sawyer.pdf\", 1)\n",
    "ts_text = remove_page_markers(ts_text)\n",
    "ts_text = remove_chapter_headers_and_citations(ts_text)\n",
    "ts_text = remove_unwanted_line_breaks(ts_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1984 = pdf_reader(\"1984.pdf\", 1)\n",
    "text_1984 = remove_chapter_headers_and_citations(text_1984)\n",
    "text_1984 = remove_unwanted_line_breaks(text_1984)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "into_air_text = open_book(\"into_thin_air\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "killing_machine_text = open_book(\"killing_machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "killing_machine_text = remove_file_paths_from_content(killing_machine_text)\n",
    "killing_machine_text = remove_initial(killing_machine_text)\n",
    "killing_machine_text = remove_specific_patterns(killing_machine_text)\n",
    "killing_machine_text = remove_unwanted_line_breaks(killing_machine_text)\n",
    "killing_machine_text = remove_hyphenation(killing_machine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "into_air_text = remove_initial_text(into_air_text)\n",
    "into_air_text = remove_unwanted_line_breaks(into_air_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stardust_text = pdf_reader(\"stardust.pdf\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stardust_text = remove_page_markers(stardust_text)\n",
    "stardust_text = remove_chapter_headers_and_citations(stardust_text)\n",
    "stardust_text = remove_unwanted_line_breaks(stardust_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stardust_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "androids_text = pdf_reader(\"androids.pdf\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "androids_text = remove_page_markers(androids_text)\n",
    "androids_text = remove_chapter_headers_and_citations(androids_text)\n",
    "androids_text = remove_unwanted_line_breaks(androids_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_txt(\"cosmos_cleaned\", cosmos_text)\n",
    "save_as_txt(\"tom_sawyer_cleaned\", ts_text)\n",
    "save_as_txt(\"into_thin_air_cleaned\", into_air_text)\n",
    "save_as_txt(\"1984_cleaned\", text_1984)\n",
    "save_as_txt(\"killing_machine_cleaned\", killing_machine_text)\n",
    "save_as_txt(\"androids_cleaned\", androids_text)\n",
    "save_as_txt(\"stardust_cleaned\", stardust_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumenwood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
