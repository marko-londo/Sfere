{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from_document(file_path, skip_items=10, strict=False):\n",
    "    \"\"\"\n",
    "    Extracts literary content from a PDF or EPUB file, with options to apply different levels of filtering.\n",
    "\n",
    "    :param file_path: Path to the PDF or EPUB file.\n",
    "    :param skip_items: Number of initial pages/items to skip.\n",
    "    :param strict: If True, applies stricter filtering criteria (useful for non-fiction works).\n",
    "    :return: Extracted literary text.\n",
    "    \"\"\"\n",
    "\n",
    "    if file_path.lower().endswith('.pdf'):\n",
    "        return extract_text_from_pdf(file_path, skip_pages=skip_items, strict=strict)\n",
    "    elif file_path.lower().endswith('.epub'):\n",
    "        return extract_text_from_epub(file_path, skip_items=skip_items)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please provide a PDF or EPUB file.\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, skip_pages=5, strict=False):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    # PDF-specific extraction logic\n",
    "    # ...\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "def extract_text_from_epub(epub_path, skip_items=10):\n",
    "    book = epub.read_epub(epub_path)\n",
    "    text = \"\"\n",
    "    # EPUB-specific extraction logic\n",
    "    # ...\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, skip_pages=0, skip_lines=0):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF document, with options to skip initial pages and lines.\n",
    "\n",
    "    :param pdf_path: Path to the PDF document.\n",
    "    :param skip_pages: Number of initial pages to skip.\n",
    "    :param skip_lines: Number of initial lines to skip on each page.\n",
    "    :return: Extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "\n",
    "    for page_number in range(skip_pages, len(doc)):\n",
    "        page = doc[page_number]\n",
    "        page_text = page.get_text(\"text\")\n",
    "        if page_text:\n",
    "            lines = page_text.split('\\n')[skip_lines:]\n",
    "            paragraph = ''\n",
    "\n",
    "            for line in lines:\n",
    "                if line.endswith(('-', '—')):  # Handling hyphenated words at line breaks\n",
    "                    paragraph += line.rstrip('-—')\n",
    "                elif line == '':\n",
    "                    if paragraph:\n",
    "                        text += paragraph.strip() + '\\n\\n'\n",
    "                        paragraph = ''\n",
    "                else:\n",
    "                    paragraph += line + ' '\n",
    "\n",
    "            if paragraph:\n",
    "                text += paragraph.strip() + '\\n\\n'\n",
    "            \n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "def open_book(filename):\n",
    "    with open(\"../../Resources/Raw/\"+filename+\".txt\", 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def extract_narrative_content_from_epub(epub_path, skip_items=10):\n",
    "    book = epub.read_epub(epub_path)\n",
    "    text = \"\"\n",
    "    item_count = 0\n",
    "\n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            item_count += 1\n",
    "            if item_count <= skip_items:\n",
    "                continue  # Skipping more initial non-narrative sections\n",
    "\n",
    "            soup = BeautifulSoup(item.content, 'html.parser')\n",
    "            paragraphs = soup.find_all('p')\n",
    "            \n",
    "            for p in paragraphs:\n",
    "                paragraph_text = p.get_text().strip()\n",
    "                if paragraph_text and not paragraph_text.isdigit() and len(paragraph_text.split()) > 3:\n",
    "                    text += paragraph_text + '\\n\\n'\n",
    "\n",
    "def save_as_txt(filename, text):\n",
    "    # Open the file in write mode and write the cleaned text\n",
    "    with open(\"../../Resources/Cleaned/\"+filename+\".txt\", 'w', encoding='utf-8') as file:\n",
    "        file.write(text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1984 = r\"C:\\Users\\dontb\\01\\001\\Repos\\Dying-Earth\\Resources\\Raw\\1984.pdf\"\n",
    "path_androids = r\"C:\\Users\\dontb\\01\\001\\Repos\\Dying-Earth\\Resources\\Raw\\androids.pdf\"\n",
    "path_stardust = r\"C:\\Users\\dontb\\01\\001\\Repos\\Dying-Earth\\Resources\\Raw\\stardust.pdf\"\n",
    "path_tom = r\"C:\\Users\\dontb\\01\\001\\Repos\\Dying-Earth\\Resources\\Raw\\tom_sawyer.pdf\"\n",
    "path_cosmos = r\"C:\\Users\\dontb\\01\\001\\Repos\\Dying-Earth\\Resources\\Raw\\cosmos.pdf\"\n",
    "path_into = r\"C:\\Users\\dontb\\01\\001\\Repos\\Dying-Earth\\Resources\\Raw\\into_thin_air.epub\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_1984 = extract_text_from_pdf(path_1984, skip_pages=0, skip_lines=2)\n",
    "txt_androids = extract_text_from_pdf(path_androids, skip_pages=2, skip_lines=0)\n",
    "txt_stardust = extract_text_from_pdf(path_stardust, skip_pages=4, skip_lines=0)\n",
    "txt_tom = extract_text_from_pdf(path_tom, skip_pages=1, skip_lines=0)\n",
    "txt_cosmos = extract_text_from_pdf(path_cosmos, skip_pages=5, skip_lines=0)\n",
    "txt_into = extract_text_from_epub(path_into, skip_items=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_txt(\"cosmos_cleaned\", txt_cosmos)\n",
    "save_as_txt(\"tom_sawyer_cleaned\", txt_tom)\n",
    "save_as_txt(\"into_thin_air_cleaned\", txt_into)\n",
    "save_as_txt(\"1984_cleaned\", txt_1984)\n",
    "save_as_txt(\"androids_cleaned\", txt_androids)\n",
    "save_as_txt(\"stardust_cleaned\", txt_stardust)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cathedral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
