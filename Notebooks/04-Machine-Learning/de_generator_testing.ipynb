{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_path = r\"C:\\Users\\dontb\\01\\001\\Repos\\Dying-Earth\\Notebooks\\04-Machine-Learning\\Models\\GPT2\\gen_model\"\n",
    "tok_path = r\"C:\\Users\\dontb\\01\\001\\Repos\\Dying-Earth\\Notebooks\\04-Machine-Learning\\Models\\GPT2\\gen_tokenizer\"\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(mod_path)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(tok_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model Name': 'C:\\\\Users\\\\dontb\\\\01\\\\001\\\\Repos\\\\Dying-Earth\\\\Notebooks\\\\04-Machine-Learning\\\\Models\\\\GPT2\\\\gen_model',\n",
       " 'Number of Parameters': 124439808,\n",
       " 'Number of Layers': 12,\n",
       " 'Hidden Size': 768,\n",
       " 'Number of Attention Heads': 12,\n",
       " 'Vocab Size': 50257,\n",
       " 'Max Sequence Length': 1024}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_specs = {\n",
    "    \"Model Name\": model.name_or_path,\n",
    "    \"Number of Parameters\": model.num_parameters(),\n",
    "    \"Number of Layers\": model.cotellnfig.n_layer,\n",
    "    \"Hidden Size\": model.config.n_embd,\n",
    "    \"Number of Attention Heads\": model.config.n_head,\n",
    "    \"Vocab Size\": model.config.vocab_size,\n",
    "    \"Max Sequence Length\": model.config.n_positions,\n",
    "}\n",
    "\n",
    "model_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\dontb\\01\\001\\Repos\\Dying-Earth\\Notebooks\\04-Machine-Learning\\prompt_starters.pickle', 'rb') as file:\n",
    "    starter_prompts = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In the ancient forest,', 'Beneath the starlit sky,', 'Amidst the rolling hills,', 'Along the winding river,', 'The mysterious stranger']\n"
     ]
    }
   ],
   "source": [
    "print(starter_prompts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A world beyond dreams, where the stars obscure the stars; where the unseen cosmos is vast and unknown; where the stars are behind bars and dark and deep and chill. Where the stars are behind bars and star-shaped, and where the stars are behind bars and star-shaped; or where the stars are in clusters and globules and are not seen except in the upper clouds.\" Cugel looked dubiously over his shoulder. \"These and a host of other matters! All of these and a thousand more, and I have vowed to deliver you this awful book.\" \"Aha!\" said Archimbaust. \"I will do my best. You have a boiled squash for a head, a fine cheese for a mouth! I have a trunk full of dreams and a hundred other dreams, and I have vowed to deliver you this book.\" \"That is a good ambition! I have dreamed of deliverance! Dream of your own, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours, or dream of yours,\n"
     ]
    }
   ],
   "source": [
    "prompt = random.choice(starter_prompts)\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "# Move input_ids to the same device as the model\n",
    "input_ids = input_ids.to(model.device)\n",
    "\n",
    "max_length = len(input_ids.tolist()[0]) + 600  # Increase max length for longer outputs\n",
    "\n",
    "# Generate and decode text\n",
    "from transformers import set_seed\n",
    "\n",
    "# Optional: Set a seed for reproducibility\n",
    "\n",
    "# Adjusting generation parameters\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=max_length,  # Updated max length\n",
    "    do_sample=True,        # Enable sampling\n",
    "    temperature=0.6,       # Adjust the temperature if needed\n",
    "    top_k=60,              # Use top-k sampling\n",
    "    top_p=0.9,            # Use top-p (nucleus) sampling\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    attention_mask=input_ids.new_ones(input_ids.shape)\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cathedral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
