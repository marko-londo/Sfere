{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stop words\n",
    "def remove_stop_words(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def pandas_df(csv):\n",
    "    df = pd.read_csv(r\"../../Resources/Cleaned/\"+csv+\".csv\")\n",
    "    return df\n",
    "\n",
    "def test(data, label):\n",
    "\n",
    "    # Preprocess the text\n",
    "    new_paragraphs = data[\"Text\"].apply(remove_stop_words).values\n",
    "\n",
    "\n",
    "    # Tokenize and pad sequences\n",
    "    new_sequences = tokenizer.texts_to_sequences(new_paragraphs)\n",
    "    new_data = pad_sequences(new_sequences, maxlen=maxlen)\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(new_data)\n",
    "    predicted_classes = [1 if prob > 0.5 else 0 for prob in predictions.ravel()]\n",
    "\n",
    "    true_labels = [label] * len(predicted_classes)\n",
    "\n",
    "    # Classification Report\n",
    "    report = classification_report(true_labels, predicted_classes, target_names=['Class 0', 'Class 1'])\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_df = pandas_df(\"dying_earth_corpus\")\n",
    "not_de_df = pandas_df(\"not_dying_earth_corpus\")\n",
    "km_df = pandas_df(\"killing_machine_paragraphs\")\n",
    "android_df = pandas_df(\"android_paragraphs\")\n",
    "stardust_df = pandas_df(\"stardust_paragraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_df[\"Is_Dying_Earth\"] = 0\n",
    "android_df[\"Is_Dying_Earth\"] = 0\n",
    "stardust_df[\"Is_Dying_Earth\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([de_df, not_de_df], axis=0, ignore_index=True)\n",
    "corpus = corpus.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Is_Dying_Earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cugel's Saga</td>\n",
       "      <td>Some days later, while strolling the esplanade...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Sawyer</td>\n",
       "      <td>Then they waited in silence for what seemed a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cosmos</td>\n",
       "      <td>If the world is to be understood, if we are to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Into Thin Air</td>\n",
       "      <td>But Frank, the gentlemanly, quiet-spoken publi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rhialto the Marvellous</td>\n",
       "      <td>\"None whatever.\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>Rhialto the Marvellous</td>\n",
       "      <td>Rhialto gazed in all directions. The music, or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8711</th>\n",
       "      <td>1984</td>\n",
       "      <td>His earlier thought returned to him: probably ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>The Dying Earth</td>\n",
       "      <td>\"Quick,\" said Guyal to Shierl. She sprang to t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8713</th>\n",
       "      <td>Cosmos</td>\n",
       "      <td>For Saturn as for Jupiter, the magnetic field ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8714</th>\n",
       "      <td>The Dying Earth</td>\n",
       "      <td>Reach your hand and take it.\" T'sais sheathed ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8715 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title  \\\n",
       "0               Cugel's Saga   \n",
       "1                 Tom Sawyer   \n",
       "2                     Cosmos   \n",
       "3              Into Thin Air   \n",
       "4     Rhialto the Marvellous   \n",
       "...                      ...   \n",
       "8710  Rhialto the Marvellous   \n",
       "8711                    1984   \n",
       "8712         The Dying Earth   \n",
       "8713                  Cosmos   \n",
       "8714         The Dying Earth   \n",
       "\n",
       "                                                   Text  Is_Dying_Earth  \n",
       "0     Some days later, while strolling the esplanade...               1  \n",
       "1     Then they waited in silence for what seemed a ...               0  \n",
       "2     If the world is to be understood, if we are to...               0  \n",
       "3     But Frank, the gentlemanly, quiet-spoken publi...               0  \n",
       "4                                      \"None whatever.\"               1  \n",
       "...                                                 ...             ...  \n",
       "8710  Rhialto gazed in all directions. The music, or...               1  \n",
       "8711  His earlier thought returned to him: probably ...               0  \n",
       "8712  \"Quick,\" said Guyal to Shierl. She sprang to t...               1  \n",
       "8713  For Saturn as for Jupiter, the magnetic field ...               0  \n",
       "8714  Reach your hand and take it.\" T'sais sheathed ...               1  \n",
       "\n",
       "[8715 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438.29833620195063"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_length = corpus['Text'].apply(len).mean()\n",
    "average_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 8715/8715 [00:00<00:00, 17558.16it/s]\n",
      "Converting to Sequences: 100%|██████████| 8715/8715 [00:00<00:00, 23635.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Applying stop word removal to each text in the corpus\n",
    "paragraphs = corpus[\"Text\"].apply(remove_stop_words).values\n",
    "\n",
    "# Tokenization\n",
    "max_words = 25000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "tokenizer.fit_on_texts(tqdm(paragraphs, desc=\"Tokenizing\"))\n",
    "sequences = tokenizer.texts_to_sequences(tqdm(paragraphs, desc=\"Converting to Sequences\"))\n",
    "\n",
    "# Padding sequences\n",
    "maxlen = 438\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# Labels\n",
    "labels = corpus[\"Is_Dying_Earth\"].values\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "# Model definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=maxlen))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "175/175 [==============================] - 37s 197ms/step - loss: 0.2922 - accuracy: 0.8668 - val_loss: 0.0875 - val_accuracy: 0.9699\n",
      "Epoch 2/10\n",
      "175/175 [==============================] - 35s 200ms/step - loss: 0.0303 - accuracy: 0.9930 - val_loss: 0.0782 - val_accuracy: 0.9692\n",
      "Epoch 3/10\n",
      "175/175 [==============================] - 35s 199ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.1101 - val_accuracy: 0.9642\n",
      "Epoch 4/10\n",
      "175/175 [==============================] - 35s 198ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 0.1006 - val_accuracy: 0.9663\n",
      "55/55 [==============================] - 3s 50ms/step - loss: 0.0848 - accuracy: 0.9730\n",
      "Test accuracy: 0.9730349779129028\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 4s 58ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       806\n",
      "           1       0.98      0.97      0.97       937\n",
      "\n",
      "    accuracy                           0.97      1743\n",
      "   macro avg       0.97      0.97      0.97      1743\n",
      "weighted avg       0.97      0.97      0.97      1743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred.ravel()]\n",
    "\n",
    "# Generating the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 40ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.77      0.87       976\n",
      "     Class 1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.77       976\n",
      "   macro avg       0.50      0.39      0.44       976\n",
      "weighted avg       1.00      0.77      0.87       976\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dontb\\Anaconda3\\envs\\cathedral\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dontb\\Anaconda3\\envs\\cathedral\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dontb\\Anaconda3\\envs\\cathedral\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test(android_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 40ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.81      0.90      1055\n",
      "     Class 1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.81      1055\n",
      "   macro avg       0.50      0.41      0.45      1055\n",
      "weighted avg       1.00      0.81      0.90      1055\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dontb\\Anaconda3\\envs\\cathedral\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dontb\\Anaconda3\\envs\\cathedral\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dontb\\Anaconda3\\envs\\cathedral\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test(stardust_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 36ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      0.39      0.56       634\n",
      "     Class 1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.39       634\n",
      "   macro avg       0.50      0.20      0.28       634\n",
      "weighted avg       1.00      0.39      0.56       634\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dontb\\Anaconda3\\envs\\cathedral\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dontb\\Anaconda3\\envs\\cathedral\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\dontb\\Anaconda3\\envs\\cathedral\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test(km_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('is_dying_earth_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tokenizer.pkl', 'wb') as tokenizer_file:\n",
    "    pickle.dump(tokenizer, tokenizer_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cathedral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
