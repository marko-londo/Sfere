{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "import stanza\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "\n",
    "books_songs =  [\n",
    "    \"Attractive and Detractive Hyperordnets\",\n",
    "    \"the Lost Book of Kells\",\n",
    "    \"The Opal, the Pearl and the Peacock\",\n",
    "    \"'The Opal, the Pearl and the Peacock\",\n",
    "    \"Demonlands\",\n",
    "    \"Killings and Mortefactions\",\n",
    "    \"Attractive and Detractive Hyperordnets\",\n",
    "    \"Procedural Suggestions in Time of Risk\",\n",
    "    \"the Tomes of Kae\",\n",
    "    \"the Word of Pansiu\"\n",
    "]\n",
    "\n",
    "artifacts_objects = [\n",
    "    \"Live Boots\",\n",
    "    \"the Live Boots\",\n",
    "    \"Cyclopedia\",\n",
    "    \"the Expansible Egg\",\n",
    "    \"Chair of Knowledge\",\n",
    "    \"Scintillant Dagger\",\n",
    "    \"Boots\",\n",
    "    \"Mechanismus\",\n",
    "    \"Rune\",\n",
    "    \"Egg\",\n",
    "    \"Sphere\"\n",
    "]\n",
    "\n",
    "spells = [\n",
    "    \"the Omnipotent Sphere\",\n",
    "    \"the Call to the Violent Cloud\",\n",
    "    \"the Excellent Prismatic Spray\",\n",
    "    \"Mantle of Stealth\",\n",
    "    \"the Spell of the Slow Hour\",\n",
    "    \"Four Directions\",\n",
    "    \"Second Hypnotic Spell\",\n",
    "    \"The Charm of Untiring Nourishment\",\n",
    "    \"Critique of the Chill\",\n",
    "    \"Gyrator\",\n",
    "    \"Lumen\",\n",
    "    \"the Call to the Violent Cloud\",\n",
    "    \"the Spell of the Omnipotent Sphere\"\n",
    "]\n",
    "\n",
    "characters = [\n",
    "    \"Pansiu's\",\n",
    "    \"Guyal\",\n",
    "    \"Kandive\",\n",
    "    \"Kandive the Golden\",\n",
    "    \"Guyal of Sfere\", \n",
    "    \"Liane the Wayfarer\", \n",
    "    \"Mazirian\", \n",
    "    \"Turjan\", \n",
    "    \"T'sais\", \n",
    "    \"Ulan Dhor\", \n",
    "    \"Elai\", \n",
    "    \"Etarr\", \n",
    "    \"Prince Kandive\", \n",
    "    \"Pandelume\", \n",
    "    \"Rogol Domedonfors\", \n",
    "    \"Shierl\", \n",
    "    \"T'sain\",\n",
    "    \"Cazdal\",\n",
    "    \"Javanne\",\n",
    "    \"Kerlin\",\n",
    "    \"the Lake Lord\",\n",
    "    \"the Arch-Necromancer Phandaal\",\n",
    "    \"Pansiu\",\n",
    "    \"Melantine\",\n",
    "    \"Voyevode\",\n",
    "    \"Kandive the Golden\",\n",
    "    \"Blikdak\",\n",
    "    \"Laccodel\",\n",
    "    \"Mad King Shin\",\n",
    "    \"Lycurgat\",\n",
    "    \"Saponid\"\n",
    "]\n",
    "\n",
    "locations = [\n",
    "    \"Ampridatvir\",\n",
    "    \"Erze Damath\",\n",
    "    \"Kaiin\",\n",
    "    \"Sanctuary of the Pelerines\",\n",
    "    \"Ascolais\",\n",
    "    \"The Scaum Valley\",\n",
    "    \"The Forest of Tantrevalles\",\n",
    "    \"Ruins of Old Romarth\",\n",
    "    \"The Cleft of the Earth\",\n",
    "    \"Overworld\",\n",
    "    \"Azenomei\",\n",
    "    \"Ulan Dhor\",\n",
    "    \"Almery\",\n",
    "    \"Embelyon\",\n",
    "    \"the Land of the Falling Wall\",\n",
    "    \"Sfere\",\n",
    "    \"Thamber\",\n",
    "    \"Kaiin\",\n",
    "    \"Miir\",\n",
    "    \"Ascolais\",\n",
    "    \"Efred\",\n",
    "    \"Jeldred\",\n",
    "    \"Saponce\",\n",
    "    \"Maurenron Range\",\n",
    "    \"Porphiron Scar\",\n",
    "    \"Omona Gap\",\n",
    "    \"East Almery\",\n",
    "    \"Bautiku\",\n",
    "    \"Tenebrosa\",\n",
    "    \"Kalu\",\n",
    "    \"Fauvune\",\n",
    "    \"Cansapara\",\n",
    "    \"South Almery\",\n",
    "    \"Ariventa\",\n",
    "    \"Sanreale\",\n",
    "    \"Tanvilkat\",\n",
    "    \"the Old Town\",\n",
    "    \"Ampridatvir\",\n",
    "    \"Mel-Palusas\",\n",
    "    \"Fer Aquila\",\n",
    "    \"Carchasel\",\n",
    "    \"Derna\",\n",
    "    \"Regatta\",\n",
    "    \"Carchesel\",\n",
    "    \"Scaum\",\n",
    "    \"Liane\",\n",
    "    \"Thorsingol\",\n",
    "    \"Peilvemchal Torrent\",\n",
    "    \"the Porphiron Scar\",\n",
    "    \"the River Scaum\",\n",
    "    \"the Ide of Kauchique\",\n",
    "    \"the Cape of Sad Remembrance\",\n",
    "    \"Thamber Meadow\",\n",
    "    \"the Lake of Dreams\",\n",
    "    \"G'Vasan\",\n",
    "    \"Melantine\"\n",
    "]\n",
    "\n",
    "facilities = [\n",
    "    \"Mansion of Chun the Unavoidable\",\n",
    "    \"the Place of Whispers\",\n",
    "    \"the Tower of Fate\",\n",
    "    \"the Tower of the Screaming Ghost\",\n",
    "    \"the Tower of Trumpets\",\n",
    "    \"the Museum of Man\",\n",
    "    \"the Cognative Repository\",\n",
    "    \"Temple\",\n",
    "    \"Caseboard\",\n",
    "    \"Museum of Man\"\n",
    "]\n",
    "\n",
    "events = [\n",
    "    \"the Black Sabbath\",\n",
    "    \"the Dance of the Fourteen Silken Movements\",\n",
    "    \"Dawn\"\n",
    "]\n",
    "\n",
    "norps = [\n",
    "    \"the Signs of the Aumoklopelastianic Cabal\",\n",
    "    \"Ghost-takers\",\n",
    "    \"Norns\",\n",
    "    \"Gaun\",\n",
    "    \"The Green Legion of Valdaran the Just\",\n",
    "    \"the Grays of Ampridatvir\",\n",
    "    \"Saponids\",\n",
    "    \"Saponid\",\n",
    "    \"the Saponids of Saponce\",\n",
    "    \"Ampridatvians\",\n",
    "    \"Grays\",\n",
    "    \"Raiders\",\n",
    "    \"the Green Legion\",\n",
    "    \"Green Legion\",\n",
    "    \"the Forty Kades\",\n",
    "    \"the Sherit Empire\",\n",
    "    \"Merioneth\",\n",
    "    \"the Gray Sorcerers\"\n",
    "]\n",
    "\n",
    "creatures = [\n",
    "    \"Deodand\",\n",
    "    \"Vile Green Demon\",\n",
    "    \"Thrang\",\n",
    "    \"Deodands\"\n",
    "    \n",
    "]\n",
    "\n",
    "other = [\n",
    "    \"Poh\",\n",
    "    \"Mark\",\n",
    "    \"Green\",\n",
    "    \"Lethargy\",\n",
    "    \"Golden\",\n",
    "    \"Aye\",\n",
    "    \"Pulchritude\",\n",
    "    \"the Mechanismus sixty\",\n",
    "    \"The Curator guards the Museum of Man\",\n",
    "    \"Curator or Museum\",\n",
    "    \"Gap\",\n",
    "    \"Wayfarer\"\n",
    "]\n",
    "\n",
    "correction_dict = {\n",
    "    \"BOOK_SONG\": books_songs,\n",
    "    \"ARTIFACT_OBJECT\": artifacts_objects,\n",
    "    \"SPELL\": spells,\n",
    "    \"PERSON\": characters,\n",
    "    \"LOC\": locations,\n",
    "    \"FAC\": facilities,\n",
    "    \"EVENT\": events,\n",
    "    \"NORP\": norps,\n",
    "    \"CREATURE\": creatures,\n",
    "    \"OTHER\": other\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def open_book(filename):\n",
    "    with open(\"../../Resources/Cleaned/\"+filename+\".txt\", 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def add_book_to_df(book, book_title):\n",
    "    # Split the book text into paragraphs\n",
    "    paragraphs = book.split('\\n')\n",
    "    \n",
    "    # Clean each paragraph by removing extra whitespace and trimming\n",
    "    paragraphs = [re.sub(r'\\s+', ' ', para.strip()) for para in paragraphs if para.strip()]\n",
    "\n",
    "    # Create a DataFrame with two columns: book title and the paragraph text\n",
    "    df = pd.DataFrame({'Title': [book_title] * len(paragraphs), 'Text': paragraphs})\n",
    "    return df\n",
    "\n",
    "def correct_entity_type(entity_text, correction_dict):\n",
    "    # Normalize the entity text (lowercase, remove extra spaces, handle special chars)\n",
    "    entity_text_normalized = re.sub(r'\\s+', ' ', entity_text).lower().strip(\" '\\\"\")\n",
    "\n",
    "    for category, names in correction_dict.items():\n",
    "        # Normalize and prepare the names in the dictionary\n",
    "        normalized_names = [re.sub(r'\\s+', ' ', name).lower().strip(\" '\\\"\") for name in names]\n",
    "        \n",
    "        if entity_text_normalized in normalized_names:\n",
    "            return category\n",
    "    return None\n",
    "\n",
    "def find_entities_in_paragraph(paragraph, entities):\n",
    "    entities_in_paragraph = set()\n",
    "    for ent_text, ent_type in entities:\n",
    "        if ent_text in paragraph:\n",
    "            entities_in_paragraph.add((ent_text, ent_type))\n",
    "    return list(entities_in_paragraph)\n",
    "\n",
    "def dialogue_to_df(text):\n",
    "    pattern = r'\"([^\"]*)\"'\n",
    "    dialogues = re.findall(pattern, text)\n",
    "    df_dialogues = pd.DataFrame(dialogues, columns=['Dialogue'])\n",
    "    return df_dialogues\n",
    "\n",
    "def key_phrase_extractor(text, n=1):\n",
    "    additional_stopwords = {'said', \"'s\", \"n't\", \"'m\", \"'re\", \"'ve\", \"'ll\", \"'d\"}\n",
    "    custom_stopwords = set(stopwords.words('english')).union(additional_stopwords)\n",
    "\n",
    "    # Tokenize the text into words, remove punctuation with regex\n",
    "    words = word_tokenize(re.sub(r'[^\\w\\s]', '', text))\n",
    "\n",
    "    # Remove stop words and convert to lowercase\n",
    "    words_without_stopwords = [word.lower() for word in words if word.lower() not in custom_stopwords]\n",
    "\n",
    "    # Generate n-grams\n",
    "    n_grams = ngrams(words_without_stopwords, n)\n",
    "    n_grams = [' '.join(grams) for grams in n_grams]\n",
    "\n",
    "    # Count the frequency of each n-gram\n",
    "    frequency = Counter(n_grams)\n",
    "\n",
    "    # Get the top N key phrases\n",
    "    N = 100\n",
    "    key_phrases = frequency.most_common(N)\n",
    "\n",
    "    # Create a DataFrame from the top key phrases\n",
    "    df = pd.DataFrame(key_phrases, columns=['phrase', 'count'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def is_character(entity):\n",
    "    character_types = {'PERSON'}\n",
    "    return entity[1] in character_types\n",
    "\n",
    "def is_location(entity):\n",
    "    location_types = {'LOC'}\n",
    "    return entity[1] in location_types\n",
    "\n",
    "\n",
    "def df_to_csv(df, filename):\n",
    "    df.to_csv(\"../../Resources/Cleaned/\"+filename+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "entities = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    entities.append((ent.text, ent.label_))\n",
    "\n",
    "df = pd.DataFrame(entities, columns=[\"Entity\", \"Entity Type\"])\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cathedral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
